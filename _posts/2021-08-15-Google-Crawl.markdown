---
layout: post
title:  "구글 검색결과 크롤링"
date:   2021-08-15 16:50:00 +0900
image:  Google_Crawl.PNG
tags:   구글 검색 구글검색 검색결과 크롤링 검색결과크롤링 구글크롤링
---


### 구글 검색결과 크롤링

***

본 크롤링 코드는 구글 검색결과중 게시글 제목과 URL을 검색결과 10페이지까지 크롤링합니다.

***

14일 밤, 엑셀로 정리된 키워드를 이용해 구글 검색 결과에서 게시글 제목과 URL을 크롤링 할 수 있겠냐는 대화가 있었다.

디테일을 여쭤보니 생각보다 간단한 구조여서 가능하다고 답변드렸고 안그래도 짧은 휴가로 심심하던 차에 잘 됐다는 생각에 멋대로 작업을 시작했다.

물론 구글 검색결과 크롤링을 진행할 수 있는 많은 코드가 나와있다. 

하지만 그 코드들을 참고하지 않고 내 맘대로 작성해보고 싶은 마음도 있었기에 즐겁게 작업을 진행했고 초보자도 사용할 수 있도록 자세한 설명과 주석을 첨가해 이곳에 공유한다.

***

### 코드 실행을 통해 얻을 수 있는 것

- 키워드 별 구글 검색결과 10페이지 분량
  - 게시물의 제목과 그 URL
  - 엑셀로 정리됨

***

### 코드 관련 참고사항

1. 윈도우 환경에서 작동한다. 이외 환경은 그 환경에 맞는 코드 수정이 필요하다.
2. 파이썬과 셀레니움, 판다스가 필요하며 크롬 브라우저가 설치되어 있어야한다.
3. 키워드는 엑셀로 정리되어야 한다. 엑셀 파일의 예시는 포함되어있다.
  - csv방식은 코드의 수정이 필요하다.
4. 여러 키워드 엑셀 파일을 동시에 사용 할 수 있다. 이때 각 키워드 엑셀 파일별 이름으로 크롤링 데이터가 저장된다. 
  - eg. A키워드.xlsx, B키워드.xlsx 파일이 동시에 존재 할 시 순차적으로 A키워드크롤링데이터.xlsx를 생성하고 B키워드크롤링데이터.xlsx를 생성한다.

***

### 코드 공유

코드는 깃허브 레포지토리에 올려두었다.

[Github](https://github.com/StrangeFate/GoogleCrawl)

사용 방법은 다음과 같다.

1. 깃허브 레포지토리내 파일중 Google_Search_Crawl.ipnyb와 chromedriver.exe, example키워드.xlsx를 다운로드 하고 동일한 폴더에 위치시킨다.
  - 또는 해당 레포지토리를 통째로 클론한다.
2. example키워드.xlsx를 열어 엑셀내 키워드 저장 방식을 참고하여 크롤링이 필요한 키워드를 추가한다.
3. Google_Search_Crawl.ipynb를 주피터 노트북으로 연다.
4. Google_Search_Crawl.ipynb내 사용설명서를 참고하여 코드를 실행한다.

***

### 코드 한계점

기존에 요구되었던 검색결과가 10페이지 분량이라 검색결과의 10페이지까지만 크롤링이 되도록 구성된 코드를 사용하고 있다. 

이 부분은 개선이 가능하나 현재로는 계획이 없다. 

***

간단한 구글 검색 결과 크롤링이 필요한 분들께 도움이 되었으면 좋겠다. 